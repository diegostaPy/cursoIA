{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import LeakyReLU, Activation, Input, Dense, Dropout, Concatenate, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import mnist\n",
    "#physical_devices = tensorflow.config.experimental.list_physical_devices('GPU')\n",
    "#tensorflow.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def build_gan(generator, discriminator, name=\"gan\"):\n",
    "    '''Build the GAN from a generator and a discriminator'''\n",
    "    yfake = Activation(\"linear\", name=\"yfake\")(discriminator(generator(generator.inputs)))\n",
    "    yreal = Activation(\"linear\", name=\"yreal\")(discriminator(discriminator.inputs))\n",
    "    model = Model(generator.inputs + discriminator.inputs, [yfake, yreal], name=name)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc(image_dim, label_dim, layer_dim=1024, reg=lambda: l1_l2(1e-5, 1e-5)):\n",
    "    '''Discriminator network'''\n",
    "    x      = (Input(shape=(image_dim,), name='discriminator_input'))\n",
    "    label  = (Input(shape=(label_dim,), name='discriminator_label'))\n",
    "    inputs = (Concatenate(name='input_concatenation'))([x, label])\n",
    "    a = (Dense(layer_dim, name=\"discriminator_h1\", kernel_regularizer=reg()))(inputs)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(int(layer_dim / 2), name=\"discriminator_h2\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(int(layer_dim / 4), name=\"discriminator_h3\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(1, name=\"discriminator_y\", kernel_regularizer=reg()))(a)\n",
    "    a = (Activation('sigmoid'))(a)\n",
    "    model = Model(inputs=[x, label], outputs=a, name=\"discriminator\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(noise_dim, label_dim, image_dim, layer_dim=1024, activ='tanh', reg=lambda: l1_l2(1e-5, 1e-5)):\n",
    "    '''Generator network'''\n",
    "    z      = (Input(shape=(noise_dim,), name='generator_input'))\n",
    "    label  = (Input(shape=(label_dim,), name='generator_label'))\n",
    "    inputs = (Concatenate(name='input_concatenation'))([z, label])\n",
    "    a = (Dense(int(layer_dim / 4), name=\"generator_h1\", kernel_regularizer=reg()))(inputs)\n",
    "    a = (LeakyReLU(0.2))(a)    # Trick 5\n",
    "    a = (Dense(int(layer_dim / 2), name=\"generator_h2\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(layer_dim, name=\"generator_h3\", kernel_regularizer=reg()))(a)\n",
    "    a = (LeakyReLU(0.2))(a)\n",
    "    a = (Dense(np.prod(image_dim), name=\"generator_x_flat\", kernel_regularizer=reg()))(a)\n",
    "    a = (Activation(activ))(a)    \n",
    "    model = Model(inputs=[z, label], outputs=[a, label], name=\"generator\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    '''Changes the trainable property of a model as a whole and layer by layer'''\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ------------------------------------------------------------------------------\n",
    "# Data preparation\n",
    "# ------------------------------------------------------------------------------\n",
    "(x_train, l_train), (x_test, l_test) = mnist.load_data()\n",
    "x_train = np.concatenate((x_train, x_test))\n",
    "l_train = np.concatenate((l_train, l_test))\n",
    "\n",
    "# Normalization according to Trick 1\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_train = (x_train - 127.5) / 127.5\n",
    "l_train = to_categorical(l_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# Parameter choice\n",
    "# ------------------------------------------------------------------------------    \n",
    "# Dimension of noise to be fed to the generator\n",
    "noise_dim = 100\n",
    "# Dimension of images generated\n",
    "image_dim = 28 * 28\n",
    "# Dimension of labels\n",
    "label_dim = 10\n",
    "\n",
    "batch_size  = 100\n",
    "num_batches = int(x_train.shape[0] / batch_size)\n",
    "num_epochs  = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# Network creation\n",
    "# ------------------------------------------------------------------------------\n",
    "# Create generator ((z, l) -> (x, l))\n",
    "generator = gen(noise_dim, label_dim, image_dim)\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "generator.compile(loss='binary_crossentropy', optimizer=adam)    # Trick 9\n",
    "\n",
    "# Create discriminator ((x, l) -> y)\n",
    "discriminator = disc(image_dim, label_dim)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='SGD')    # Trick 9\n",
    "\n",
    "# Build GAN. Note how the discriminator is set to be not trainable since the beginning\n",
    "make_trainable(discriminator, False)\n",
    "gan = build_gan(generator, discriminator)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "# ------------------------------------------------------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "    for index in range(num_batches):\n",
    "        # Train the discriminator. It looks like training works best if it is trained first on only real data, and then only\n",
    "        # on fake data, so let's do that. This is Trick 4.\n",
    "        make_trainable(discriminator, True)\n",
    "        # Train dicriminator on real data\n",
    "        batch       = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
    "        image_batch = x_train[batch]\n",
    "        label_batch = l_train[batch]\n",
    "        y_real      = np.ones(batch_size) + 0.2 * np.random.uniform(-1, 1, size=batch_size)    # Label smoothing. Trick 6\n",
    "        discriminator.train_on_batch([image_batch, label_batch], y_real)\n",
    "        # Train the discriminator on fake data\n",
    "        noise_batch      = np.random.normal(0, 1, (batch_size, noise_dim))    # Trick 3\n",
    "        generated_images = generator.predict([noise_batch, label_batch])\n",
    "        y_fake           = np.zeros(batch_size) + 0.2 * np.random.uniform(0, 1, size=batch_size)    # Label smoothing\n",
    "        d_loss = discriminator.train_on_batch(generated_images, y_fake)   # Recall that generated_images already contains the labels\n",
    "        # Train the generator. We train it through the whole model. There is a very subtle point here. We want to minimize the error\n",
    "        # of the discriminator, but on the other hand we want to have the generator maximizing the loss of the discriminator (make him\n",
    "        # not capable of distinguishing which images are real). One way to achieve this is to change the loss function of the generator\n",
    "        # by some kind of \"negative loss\", which in practice is implemented by switching the labels of the real and the fake\n",
    "        # images. Note that when training the discriminator we were doing the assignment real_image->1, fake_image->0, so now\n",
    "        # we will do real_image->0, fake_image->1. The order of the outputs is [fake, real], as given by build_gan(). This is Trick 2.\n",
    "        make_trainable(discriminator, False)\n",
    "        gan_loss = gan.train_on_batch([noise_batch, label_batch, image_batch, label_batch], [y_real, y_fake])\n",
    "\n",
    "        print(\n",
    "            \"Batch {}/{}: Discriminator loss = {}, GAN loss = {}\".format(index + 1, num_batches, d_loss,\n",
    "                                                                         gan_loss))\n",
    "# Save weights. Just saving the whole GAN should work as well\n",
    "generator.save_weights('generator_cGAN.h5')\n",
    "discriminator.save_weights('discriminator_cGAN.h5')\n",
    "gan.save_weights('gan_cGAN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Plotting\n",
    "# ------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(label_dim):\n",
    "    im = generator.predict([np.random.uniform(-1, 1, (1, noise_dim)), to_categorical(i, label_dim)])[0].reshape((28, 28))\n",
    "    plt.subplot(1, label_dim, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(im, cmap='Greys_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
