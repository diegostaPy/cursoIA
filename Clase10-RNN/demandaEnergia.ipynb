{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75737668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\Anaconda\\envs\\deepf\\lib\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras._tf_keras.keras.losses' has no attribute 'mean_absolute_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 99\u001b[0m\n\u001b[0;32m     90\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(hist_window, num_units, \u001b[38;5;28mlen\u001b[39m(features), dropout)\n\u001b[0;32m     92\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     93\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     94\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mLearningRateScheduler(lr_step_decay)\n\u001b[0;32m     95\u001b[0m ]\n\u001b[0;32m     97\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     98\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m---> 99\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean_absolute_error\u001b[49m,  \u001b[38;5;66;03m# Mean Absolute Error\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mRootMeanSquaredError()]\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    104\u001b[0m     x_train, y_train,\n\u001b[0;32m    105\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    111\u001b[0m )\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Predicciones y evaluación\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras.losses' has no attribute 'mean_absolute_error'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración de semillas para reproducibilidad\n",
    "SEED = 7\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# Configuración de GPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def preparar_datos(tamanio_ventana, horizonte, data):\n",
    "    \"\"\"Prepara los datos para entrenamiento\"\"\"\n",
    "    n_features = len(data.columns)\n",
    "    n_samples = (len(data) - tamanio_ventana - horizonte + 1) // horizonte + 1\n",
    "    \n",
    "    x_train = np.zeros((n_samples, tamanio_ventana, n_features))\n",
    "    y_train = np.zeros((n_samples, horizonte))\n",
    "    \n",
    "    for i in range(tamanio_ventana, len(data) - horizonte + 1, horizonte):\n",
    "        idx = (i - tamanio_ventana) // horizonte\n",
    "        x_train[idx, :, :] = data.iloc[(i - tamanio_ventana):i, :]\n",
    "        y_train[idx, :] = data['SIN'].iloc[i:(i + horizonte)]\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "def create_model(tamanio_ventana, cantidad_unidades, nfeatures, dropout):\n",
    "    \"\"\"Crea el modelo BiGRU\"\"\"\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Bidirectional(\n",
    "            keras.layers.GRU(cantidad_unidades),\n",
    "            input_shape=(tamanio_ventana, nfeatures)\n",
    "        ),\n",
    "        keras.layers.Dropout(rate=dropout),\n",
    "        keras.layers.Dense(24)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    \"\"\"Programa de decay para learning rate\"\"\"\n",
    "    initial_learning_rate = 5e-4\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10\n",
    "    return initial_learning_rate * (drop ** (epoch // epochs_drop))\n",
    "\n",
    "# Cargar y preparar datos\n",
    "df = pd.read_csv(\"processed_dataset.csv\", index_col=\"Date\")\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Crear features temporales\n",
    "df[\"Month_sin\"] = np.sin(2 * np.pi * df.index.month / 12)\n",
    "df[\"Month_cos\"] = np.cos(2 * np.pi * df.index.month / 12)\n",
    "df[\"Year\"] = df.index.year\n",
    "\n",
    "# Seleccionar features\n",
    "features = [\"SIN\", \"Temperature\", \"Humidity\", \"Month_sin\", \"Month_cos\", \"Year\"]\n",
    "datos_norm = df[features]\n",
    "\n",
    "# Configuración de parámetros\n",
    "hist_window = 336\n",
    "num_units = 48\n",
    "batch_size = 16\n",
    "learning_rate = 5e-4\n",
    "dropout = 0.2\n",
    "epochs = 150\n",
    "pred_window = 24\n",
    "\n",
    "# Preparar datos\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(datos_norm.loc['2009-01-01':'2022-12-31'])\n",
    "\n",
    "# Datos de entrenamiento\n",
    "train = datos_norm.loc['2009-01-01':'2019-12-31']\n",
    "train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns, index=train.index)\n",
    "x_train, y_train = preparar_datos(hist_window, pred_window, train_scaled)\n",
    "\n",
    "# Datos de validación\n",
    "val = datos_norm.loc['2020-01-01':'2022-12-31']\n",
    "val_scaled = pd.DataFrame(scaler.transform(val), columns=val.columns, index=val.index)\n",
    "x_val, y_val = preparar_datos(hist_window, pred_window, val_scaled)\n",
    "\n",
    "# Crear y entrenar modelo\n",
    "model = create_model(hist_window, num_units, len(features), dropout)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True),\n",
    "    keras.callbacks.LearningRateScheduler(lr_step_decay)\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss=\"mae\",  # Mean Absolute Error\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Predicciones y evaluación\n",
    "predictions = model.predict(x_val)\n",
    "\n",
    "# Revertir scaling para evaluación\n",
    "predictions_original = scaler.inverse_transform(\n",
    "    np.hstack((predictions.reshape(-1, 1), np.zeros((predictions.size, len(features) - 1))))\n",
    ")[:, 0]\n",
    "\n",
    "y_validation_original = scaler.inverse_transform(\n",
    "    np.hstack((y_val.reshape(-1, 1), np.zeros((y_val.size, len(features) - 1))))\n",
    ")[:, 0]\n",
    "\n",
    "# Métricas de evaluación\n",
    "mae = mean_absolute_error(y_validation_original, predictions_original)\n",
    "mse = mean_squared_error(y_validation_original, predictions_original)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_validation_original, predictions_original)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "# Gráfico simple de comparación\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(y_validation_original[:100], label='Real', color='red', alpha=0.7)\n",
    "plt.plot(predictions_original[:100], label='Predicho', alpha=0.7)\n",
    "plt.title('Comparación: Valores Reales vs Predichos')\n",
    "plt.xlabel('Muestras')\n",
    "plt.ylabel('SIN (MW)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Guardar modelo\n",
    "model.save(\"modelo_simplificado.h5\")\n",
    "print(\"Modelo guardado como 'modelo_simplificado.h5'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
